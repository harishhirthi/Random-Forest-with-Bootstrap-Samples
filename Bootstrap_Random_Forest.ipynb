{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AjzGopb_YcKR"
   },
   "source": [
    "# Application of Bootstrap samples in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZSCtDI6YcKT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "from random import randint\n",
    "random.seed = 42\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2Y1Z1DoYcKZ"
   },
   "source": [
    " <li> Load the boston house dataset </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBWRNKCDYcKb"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DTbK20-mWYHU",
    "outputId": "b473b251-a104-44df-f6c3-3427184c9042"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JJ_FwP7xYcKg"
   },
   "source": [
    "### Task: 1\n",
    "<font color='red'><b>Step 1 Creating samples: </b></font> Randomly create 30 samples from the whole boston data points.\n",
    "<ol>\n",
    "<li>Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points</li>\n",
    "<li>Ex: For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly consider we have selected [4, 5, 7, 8, 9, 3] now we will replciate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]</li>\n",
    "<li> we create 30 samples like this </li>\n",
    "<li> Note that as a part of the Bagging when you are taking the random samples make sure each of the sample will have                different set of columns</li>\n",
    "<li> Ex: assume we have 10 columns for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample [7, 9, 1, 4, 5, 6, 2] and so on...</li>\n",
    "<li> Make sure each sample will have atleast 3 feautres/columns/attributes</li>\n",
    "</ol>\n",
    "\n",
    "<font color='red'><b>Step 2 Building High Variance Models on each of the sample and finding train MSE value:</b></font> Build a DecisionTreeRegressor on each of the sample.\n",
    "<ol><li>Build a regression trees on each of 30 samples.</li>\n",
    "<li>computed the predicted values of each data point(506 data points) in your corpus.</li>\n",
    "<li> predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.</li>\n",
    "<li>Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$.</li>\n",
    "</ol>\n",
    "\n",
    "<font color='red'><b>Step 3 Calculating the OOB score :</b></font>\n",
    "<ol>\n",
    "<li>Computed the predicted values of each data point(506 data points) in your corpus.</li>\n",
    "<li>Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.</li>\n",
    "<li>Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$.</li>\n",
    "</ol>\n",
    "\n",
    "### Task: 2\n",
    "<pre>\n",
    "<font color='red'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "<ol>\n",
    "<li> Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>\n",
    "</pre>\n",
    "### Task: 3\n",
    "<pre>\n",
    "<font color='red'><b>Given a single query point predict the price of house.</b></font>\n",
    "\n",
    "<li>Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] Predict the house price for this point as mentioned in the step 2 of Task 1. </li>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Row Sampling and Column Sampling for creating n Samples\n",
    "def Sampling(n):\n",
    "    index = []\n",
    "    cols = []\n",
    "    for i in range(0, n):\n",
    "        id1 = random.sample(range(0, len(x)), 303)\n",
    "        id2 = random.sample(id1, 203)\n",
    "        index_row = (id1 + id2)\n",
    "        col = random.sample(range(0, x.shape[1]), randint(3, x.shape[1]))\n",
    "        index.append(index_row)\n",
    "        cols.append(col)\n",
    "    return index, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def RFT(index, cols, x, y):\n",
    "    y_pred = {k:v for k, v in zip(range(0, len(index[0])), np.zeros(len(index[0])))}\n",
    "    counts = {k:v for k, v in zip(range(0, len(index[0])), np.zeros(len(index[0])))}\n",
    "    y_pred_ib = 0\n",
    "    y_pred_oob = []\n",
    "    for ind, col in zip(index, cols):\n",
    "        x_new = x[:, col]\n",
    "        X_new = x[ind, :][:, col]\n",
    "        Y_new = y[ind]\n",
    "        DTR = DecisionTreeRegressor()\n",
    "        DTR.fit(X_new, Y_new)\n",
    "        y_pred_ib += DTR.predict(x_new) # Calculating y_pred for mse\n",
    "\n",
    "        \n",
    "        for i in range(0, len(x)):\n",
    "            if np.all(i not in ind):\n",
    "                temp1 = y_pred[i] \n",
    "                temp1 += DTR.predict(x_new[i].reshape(1, -1)) # Calculating y_pred for oob points\n",
    "                y_pred[i] = temp1 \n",
    "            count = ind.count(i)\n",
    "            count1 = np.ceil(count / 2)\n",
    "            temp2 = counts[i]\n",
    "            count = count1 + temp2\n",
    "            counts[i] = count\n",
    "\n",
    "    y_pred_ib = y_pred_ib / len(index) # Average of y_pred for mse\n",
    "    for key, value in zip(counts.keys(), y_pred.values()):\n",
    "        y_pred_oob.append(value / (len(index) - counts[key])) # k-Avg of y_pred for mse\n",
    "    y_pred_oob = np.array(y_pred_oob).ravel() \n",
    "    \n",
    "    return y_pred_ib, y_pred_oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes, columns = Sampling(30) # Creating 30 samples\n",
    "y_pred_mse, y_pred_oob = RFT(indexes, columns, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  2.016079771359799\n",
      "OOB_Score :  11.715156916910528\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE : \", mean_squared_error(y, y_pred_mse))\n",
    "print(\"OOB_Score : \", mean_squared_error(y, y_pred_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = []\n",
    "OOB = []\n",
    "\n",
    "for i in range(0, 35):\n",
    "    indexes, columns = Sampling(30)\n",
    "    y_pred_mse, y_pred_oob = RFT(indexes, columns, x, y)\n",
    "    \n",
    "    mse = mean_squared_error(y, y_pred_mse)\n",
    "    oob = mean_squared_error(y, y_pred_oob)\n",
    "    \n",
    "    MSE.append(mse)\n",
    "    OOB.append(oob)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = np.array(MSE)\n",
    "OOB = np.array(OOB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval of MSE is 2.299 to 2.502\n"
     ]
    }
   ],
   "source": [
    "# Confidence Interval for MSE \n",
    "sample_mean = MSE.mean()\n",
    "sample_std =  MSE.std()\n",
    "sample_size = len(MSE)\n",
    "# here we are using sample standard deviation instead of population standard deviation\n",
    "left_limit  = np.round(sample_mean - 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "right_limit = np.round(sample_mean + 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "print('95% Confidence Interval of MSE is', left_limit, 'to', right_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval of OOB is 13.193 to 14.023\n"
     ]
    }
   ],
   "source": [
    "# Confidence Interval for OOB\n",
    "sample_mean = OOB.mean()\n",
    "sample_std =  OOB.std()\n",
    "sample_size = len(OOB)\n",
    "# here we are using sample standard deviation instead of population standard deviation\n",
    "left_limit  = np.round(sample_mean - 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "right_limit = np.round(sample_mean + 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "print('95% Confidence Interval of OOB is', left_limit, 'to', right_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price of xq is:  [20.452]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the price of xq\n",
    "xq = [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60]\n",
    "xq = np.array(xq)\n",
    "y_pred_ib = 0\n",
    "\n",
    "for ind, col in zip(indexes, columns):\n",
    "        x_new = xq[col]\n",
    "        X_new = x[ind, :][:, col]\n",
    "        Y_new = y[ind]\n",
    "        DTR = DecisionTreeRegressor()\n",
    "        DTR.fit(X_new, Y_new)\n",
    "        y_pred_ib += DTR.predict(x_new.reshape(1, -1))\n",
    "        \n",
    "y_pred_ib = y_pred_ib / len(indexes)\n",
    "print('Price of xq is: ', y_pred_ib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootstrap_Random_Forest_instructions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
